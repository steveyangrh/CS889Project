{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siftTrack(trainImg,trainKP,trainDesc,QueryImgBGR,h,w):\n",
    "    MIN_MATCH_COUNT=50\n",
    "\n",
    "    detector=cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    FLANN_INDEX_KDITREE=0\n",
    "    flannParam=dict(algorithm=FLANN_INDEX_KDITREE,tree=5)\n",
    "    searchParam = dict(checks=50)\n",
    "    #flann=cv2.FlannBasedMatcher(flannParam,searchParam)\n",
    "    flann=cv2.FlannBasedMatcher(flannParam,{})\n",
    "\n",
    "    #trainImg=cv2.imread(\"demo0.png\",0)\n",
    "    #trainKP,trainDesc=detector.detectAndCompute(trainImg,None)\n",
    "\n",
    "    #cam=cv2.VideoCapture(0)\n",
    "    #while True:\n",
    "    #ret, QueryImgBGR=cam.read()\n",
    "    \n",
    "    QueryImg=cv2.cvtColor(QueryImgBGR,cv2.COLOR_BGR2GRAY)\n",
    "    queryKP,queryDesc=detector.detectAndCompute(QueryImg,None)\n",
    "    matches=flann.knnMatch(queryDesc,trainDesc,k=2)\n",
    "\n",
    "    goodMatch=[]\n",
    "    queryBorder = None\n",
    "    qp = None\n",
    "    for m,n in matches:\n",
    "        if(m.distance < 0.75*n.distance):\n",
    "            goodMatch.append(m)\n",
    "    if(len(goodMatch) > MIN_MATCH_COUNT):\n",
    "        tp=[]\n",
    "        qp=[]\n",
    "        for m in goodMatch:\n",
    "            tp.append(trainKP[m.trainIdx].pt)\n",
    "            qp.append(queryKP[m.queryIdx].pt)\n",
    "        tp,qp=np.float32((tp,qp))\n",
    "        H,status=cv2.findHomography(tp,qp,cv2.RANSAC,3.0)\n",
    "        \n",
    "        #h,w=trainImg.shape\n",
    "        trainBorder=np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])\n",
    "        queryBorder=cv2.perspectiveTransform(trainBorder,H)\n",
    "        cv2.polylines(QueryImgBGR,[np.int32(queryBorder)],True,(0,255,0),5)\n",
    "        return (1,queryBorder,qp)\n",
    "        #print(queryBorder)\n",
    "    else:\n",
    "        #print(\"Not Enough match found\")\n",
    "        return (-1,queryBorder,qp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOrientation(qp):\n",
    "    tl = qp[0][0] #top left\n",
    "    bl = qp[0][1] #botton left\n",
    "    br = qp[0][2] #botton right\n",
    "    tr = qp[0][3] #top right\n",
    "    center = [(t1[0]+br[0])/2,(t1[1]+br[1])/2]\n",
    "    return center\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n",
      "NO\n",
      "NO\n",
      "[ 887.79364014  331.79214478]\n",
      "[ 908.36956787  744.36608887]\n",
      "[ 1196.58215332   726.0848999 ]\n",
      "[ 1158.37854004   302.68963623]\n",
      "YES\n",
      "[ 954.41827393  325.73849487]\n",
      "[ 971.36224365  744.77478027]\n",
      "[ 1266.0345459    734.93908691]\n",
      "[ 1231.91040039   303.93533325]\n",
      "YES\n",
      "[ 934.41021729  322.9538269 ]\n",
      "[ 953.39141846  746.12512207]\n",
      "[ 1249.02380371   732.87054443]\n",
      "[ 1212.69873047   298.9881897 ]\n",
      "YES\n",
      "[ 931.05932617  327.35232544]\n",
      "[ 952.4541626   752.71783447]\n",
      "[ 1247.7434082    738.87359619]\n",
      "[ 1210.29162598   301.80886841]\n",
      "YES\n",
      "[ 913.61437988  321.53536987]\n",
      "[ 936.14923096  744.74279785]\n",
      "[ 1231.2479248    728.76550293]\n",
      "[ 1192.0078125    294.93096924]\n",
      "YES\n",
      "[ 898.5916748   345.98937988]\n",
      "[ 926.0234375   774.42272949]\n",
      "[ 1221.55627441   754.79656982]\n",
      "[ 1176.66552734   315.49102783]\n",
      "YES\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "img1 = cv2.imread(\"demo.jpg\")\n",
    "#img3 = cv2.imread(\"demo0.png\")\n",
    "h,w,d = img1.shape\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "while True:\n",
    "    ret, img2=cam.read()\n",
    "    checker,dst,qp = siftTrack(img1,kp1,des1,img2,h,w)\n",
    "    mask = np.zeros_like(img2)\n",
    "    if checker != -1:\n",
    "        center = findOrientation(qp)\n",
    "        res = cv2.resize(img, None, fx=2, fy=2, interpolation = cv.INTER_AREA)\n",
    "        print(\"YES\")\n",
    "    else:\n",
    "        print(\"NO\")\n",
    "    keypressed = cv2.waitKey(5)\n",
    "    if keypressed == 27:\n",
    "        break\n",
    "    cv2.imshow('mask',img2)\n",
    "    \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import freenect\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pygame\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video():\n",
    "    array,_ = freenect.sync_get_video()\n",
    "    array = cv2.cvtColor(array,cv2.COLOR_RGB2BGR)\n",
    "    return array\n",
    " \n",
    "#function to get depth image from kinect\n",
    "def get_depth():\n",
    "    array,_ = freenect.sync_get_depth()\n",
    "#     np.clip(array, 0, 2**10-1, array)\n",
    "    array = array.astype(np.uint8)\n",
    "    return array\n",
    "\n",
    "def imshow(img, title = ''):\n",
    "    # hide the x and y axis for images\n",
    "    plt.axis('off')\n",
    "    # RGB images are actually BGR in OpenCV, so convert before displaying\n",
    "    if len(img.shape) == 3: \n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    # otherwise, assume it's grayscale and just display it\n",
    "    else:\n",
    "        plt.imshow(img,cmap='gray')\n",
    "    # add a title if specified\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deg2rad(angle_deg):\n",
    "    \"\"\"Convert degrees to radians\n",
    "        This method converts an angle in radians e[0,2*np.pi) into degrees\n",
    "        e[0,360)\n",
    "    \"\"\"\n",
    "    return angle_deg/180.0*np.pi\n",
    "\n",
    "def angle_rad(v1, v2):\n",
    "    \"\"\"Angle in radians between two vectors\n",
    "        This method returns the angle (in radians) between two array-like\n",
    "        vectors using the cross-product method, which is more accurate for\n",
    "        small angles than the dot-product-acos method.\n",
    "    \"\"\"\n",
    "    return np.arctan2(np.linalg.norm(np.cross(v1, v2)), np.dot(v1, v2))\n",
    "\n",
    "def detect_num_fingers(contours, defects, img_draw):\n",
    "    \"\"\"Detects the number of extended fingers\n",
    "        This method determines the number of extended fingers based on a\n",
    "        contour and convexity defects.\n",
    "        It will annotate an RGB color image of the segmented arm region\n",
    "        with all relevant defect points and the hull.\n",
    "        :param contours: a list of contours\n",
    "        :param defects: a list of convexity defects\n",
    "        :param img_draw: an RGB color image to be annotated\n",
    "        :returns: (num_fingers, img_draw) the estimated number of extended\n",
    "                  fingers and an annotated RGB color image\n",
    "    \"\"\"\n",
    "\n",
    "    # if there are no convexity defects, possibly no hull found or no\n",
    "    # fingers extended\n",
    "    thresh_deg = 80\n",
    "    if defects is None:\n",
    "        return [0, img_draw]\n",
    "\n",
    "    # we assume the wrist will generate two convexity defects (one on each\n",
    "    # side), so if there are no additional defect points, there are no\n",
    "    # fingers extended\n",
    "    if len(defects) <= 2:\n",
    "        return [0, img_draw]\n",
    "\n",
    "    # if there is a sufficient amount of convexity defects, we will find a\n",
    "    # defect point between two fingers so to get the number of fingers,\n",
    "    # start counting at 1\n",
    "    num_fingers = 1\n",
    "\n",
    "    for i in range(defects.shape[0]):\n",
    "        # each defect point is a 4-tuple\n",
    "        start_idx, end_idx, farthest_idx, _ = defects[i, 0]\n",
    "        start = tuple(contours[start_idx][0])\n",
    "        end = tuple(contours[end_idx][0])\n",
    "        far = tuple(contours[farthest_idx][0])\n",
    "\n",
    "        # draw the hull\n",
    "        cv2.line(img_draw, start, end, [0, 255, 0], 2)\n",
    "\n",
    "        # if angle is below a threshold, defect point belongs to two\n",
    "        # extended fingers\n",
    "        if angle_rad(np.subtract(start, far),\n",
    "                     np.subtract(end, far)) < deg2rad(thresh_deg):\n",
    "            # increment number of fingers\n",
    "            num_fingers = num_fingers + 1\n",
    "\n",
    "            # draw point as green\n",
    "            cv2.circle(img_draw, far, 5, [0, 255, 0], -1)\n",
    "        else:\n",
    "            # draw point as red\n",
    "            cv2.circle(img_draw, far, 5, [255, 0, 0], -1)\n",
    "\n",
    "    # make sure we cap the number of fingers\n",
    "    cv2.putText(img_draw,str(num_fingers),(10,500), cv2.FONT_HERSHEY_SIMPLEX, 4,(0,0,255),2,cv2.LINE_AA)\n",
    "    return (min(5, num_fingers), img_draw)\n",
    "\n",
    "\n",
    "def find_hull_defects(segment):\n",
    "    \"\"\"Find hull defects\n",
    "        This method finds all defects in the hull of a segmented arm\n",
    "        region.\n",
    "        :param segment: a binary image (mask) of a segmented arm region,\n",
    "                        where arm=255, else=0\n",
    "        :returns: (max_contour, defects) the largest contour in the image\n",
    "                  and all corresponding defects\n",
    "    \"\"\"\n",
    "    _, contours, hierarchy = cv2.findContours(segment, cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # find largest area contour\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    epsilon = 0.01*cv2.arcLength(max_contour, True)\n",
    "    max_contour = cv2.approxPolyDP(max_contour, epsilon, True)\n",
    "\n",
    "    # find convexity hull and defects\n",
    "    hull = cv2.convexHull(max_contour, returnPoints=False)\n",
    "    defects = cv2.convexityDefects(max_contour, hull)\n",
    "\n",
    "    return (max_contour, defects)\n",
    "\n",
    "def recognize(img_gray):\n",
    "    segment = segment_arm(img_gray)\n",
    "    (contours, defects) = find_hull_defects(segment)\n",
    "    img_draw = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n",
    "    (num_fingers, img_draw) = detect_num_fingers(contours, defects, img_draw)\n",
    "    return (num_fingers, img_draw)\n",
    "    \n",
    "\n",
    "def segment_arm(frame):\n",
    "    \"\"\"Segments arm region\n",
    "        This method accepts a single-channel depth image of an arm and\n",
    "        hand region and extracts the segmented arm region.\n",
    "        It is assumed that the hand is placed in the center of the image.\n",
    "        :param frame: single-channel depth image\n",
    "        :returns: binary image (mask) of segmented arm region, where\n",
    "                  arm=255, else=0\n",
    "    \"\"\"\n",
    "    height, width = frame.shape\n",
    "    abs_depth_dev = 15\n",
    "    # find center (21x21 pixel) region of image frame\n",
    "    center_half = 10  # half-width of 21 is 21/2-1\n",
    "    center = frame[int(height/2)-center_half:int(height/2)+center_half,\n",
    "                   int(width/2)-center_half:int(width/2)+center_half]\n",
    "\n",
    "    # find median depth value of center region\n",
    "    med_val = np.median(center)\n",
    "\n",
    "    # try this instead:\n",
    "    frame = np.where(abs(frame-med_val) <= abs_depth_dev,\n",
    "                     128, 0).astype(np.uint8)\n",
    "\n",
    "    # morphological\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    frame = cv2.morphologyEx(frame, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # connected component\n",
    "    small_kernel = 3\n",
    "    frame[int(height/2)-small_kernel:int(height/2)+small_kernel,\n",
    "         int(width/2)-small_kernel:int(width/2)+small_kernel] = 128\n",
    "\n",
    "    mask = np.zeros((height+2, width+2), np.uint8)\n",
    "    flood = frame.copy()\n",
    "    cv2.floodFill(flood, mask, (int(width/2), int(height/2)), 255,\n",
    "                  flags=4 | (255 << 8))\n",
    "\n",
    "    ret, flooded = cv2.threshold(flood, 129, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return flooded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    #get a frame from RGB camera\n",
    "    frame = get_video()\n",
    "    #get a frame from depth sensor\n",
    "    depth = get_depth()\n",
    "    height, width = depth.shape\n",
    "#     cv2.imshow('RGB image',frame)\n",
    "#     cv2.imshow('Depth image',depth)\n",
    "    num_fingers, hand = recognize(depth)\n",
    "    cv2.imshow(\"depth\", hand)\n",
    "#     num_fingers, img_draw = hand_gestures.recognize(depth)\n",
    "#     cv2.rectangle(img_draw, (width/3, height/3), (width*2/3,height*2/3), [255, 102, 0], 2)\n",
    "\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

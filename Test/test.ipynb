{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from helpers import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORB Functions\n",
    "\"\"\" Clear matches for which NN ratio is > than threshold \"\"\"\n",
    "def filter_distance(matches,ratio):\n",
    "    dist = [m.distance for m in matches]\n",
    "    thres_dist = (sum(dist) / len(dist)) * ratio\n",
    "\n",
    "    # keep only the reasonable matches\n",
    "    sel_matches = [m for m in matches if m.distance < thres_dist]\n",
    "    #print '#selected matches:%d (out of %d)' % (len(sel_matches), len(matches))\n",
    "    return sel_matches\n",
    "\n",
    "\"\"\" keep only symmetric matches \"\"\"\n",
    "def filter_asymmetric(matches, matches2):\n",
    "    sel_matches = []\n",
    "    for match1 in matches:\n",
    "        for match2 in matches2:\n",
    "            if k_ftr[match1.queryIdx] == k_ftr[match2.trainIdx] and k_scene[match1.trainIdx] == k_scene[match2.queryIdx]:\n",
    "                sel_matches.append(match1)\n",
    "                break\n",
    "    return sel_matches\n",
    "\n",
    "# Todo: filter_ransac\n",
    "\n",
    "def filter_matches(matches, matches2):\n",
    "    matches = filter_distance(matches)\n",
    "    matches2 = filter_distance(matches2)\n",
    "    return filter_asymmetric(matches, matches2)\n",
    "\n",
    "def recArea(dst):\n",
    "    qp = dst\n",
    "    #tl = qp[0][0] #top left\n",
    "    #bl = qp[0][1] #botton left\n",
    "    #br = qp[0][2] #botton right\n",
    "    #tr = qp[0][3] #top right\n",
    "    qp = qp[0] #qp stores all the points\n",
    "    area = 0\n",
    "    j = 3\n",
    "    for i in range(4):\n",
    "        area = area + (qp[j][0]+qp[i][0])*(qp[j][1]-qp[i][1])\n",
    "        j = i\n",
    "    return area/2\n",
    "\n",
    "def orbTrack(trainImg,trainKP,trainDesc,QueryImgBGR,h,w):\n",
    "    MIN_MATCH_COUNT=15\n",
    "\n",
    "    detector=cv2.ORB_create()\n",
    "\n",
    "    #FLANN_INDEX_KDITREE=0\n",
    "    #flannParam=dict(algorithm=FLANN_INDEX_KDITREE,tree=5)\n",
    "    #searchParam = dict(checks=50)\n",
    "    #flann=cv2.FlannBasedMatcher(flannParam,searchParam)\n",
    "    #flann=cv2.FlannBasedMatcher(flannParam,{})\n",
    "    \n",
    "    QueryImg=cv2.cvtColor(QueryImgBGR,cv2.COLOR_BGR2GRAY)\n",
    "    queryKP,queryDesc=detector.detectAndCompute(QueryImg,None)\n",
    "    #matches=flann.knnMatch(queryDesc,trainDesc,k=2)\n",
    "    \n",
    "    # create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    # Match descriptors.\n",
    "    #matches = bf.knnMatch(queryDesc,trainDesc)\n",
    "    goodMatchA = bf.match(queryDesc,trainDesc)\n",
    "    #goodMatchB = bf.match(trainDesc,queryDesc)\n",
    "    goodMatch = filter_distance(goodMatchA,ratio=0.65)\n",
    "    #goodMatchB = filter_distance(goodMatchB,ratio=0.65)\n",
    "    #filter distance\n",
    "    \n",
    "    # Sort them in the order of their distance.\n",
    "    # matches = sorted(matches, key = lambda x:x.distance)\n",
    "    queryBorder = None\n",
    "    qp = None\n",
    "    #print(goodMatch[0]) \n",
    "    \n",
    "    #goodMatch = filter_matches(goodMatchA,goodMatchB)\n",
    "    #print(len(goodMatch)) \n",
    "    if(len(goodMatch) > MIN_MATCH_COUNT):\n",
    "        tp=[]\n",
    "        qp=[]\n",
    "        for m in goodMatch:\n",
    "            tp.append(trainKP[m.trainIdx].pt)\n",
    "            qp.append(queryKP[m.queryIdx].pt)\n",
    "        tp,qp=np.float32((tp,qp))\n",
    "        H,status=cv2.findHomography(tp,qp,cv2.RANSAC,3.0)\n",
    "        \n",
    "        #h,w=trainImg.shape\n",
    "        trainBorder=np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])\n",
    "        queryBorder=cv2.perspectiveTransform(trainBorder,H)\n",
    "        cv2.polylines(QueryImgBGR,[np.int32(queryBorder)],True,(0,255,0),5)\n",
    "        return (1,queryBorder,qp)\n",
    "        #print(queryBorder)\n",
    "    else:\n",
    "        #print(\"Not Enough match found\")\n",
    "        return (-1,queryBorder,qp)\n",
    "    \n",
    "def findOrientation(dst):\n",
    "    qp = dst\n",
    "    tl = qp[0][0] #top left\n",
    "    bl = qp[0][1] #botton left\n",
    "    br = qp[0][2] #botton right\n",
    "    tr = qp[0][3] #top right\n",
    "    center = [(tl[0]+br[0])/2,(tl[1]+br[1])/2]\n",
    "    x1 = bl[0]\n",
    "    x2 = br[0]\n",
    "    y1 = bl[1]\n",
    "    y2 = br[1]\n",
    "    if y1 >= y2:\n",
    "        l = x2 - x1 \n",
    "        h = y1 - y2\n",
    "        theta = np.arctan(l/h)/np.pi*360\n",
    "    else:\n",
    "        l = x2 - x1\n",
    "        h = y2 - y1\n",
    "        theta = 360-(np.arctan(l/h)/np.pi*360)\n",
    "    \n",
    "    if theta < 180:\n",
    "        theta = 90-(theta/2)\n",
    "    else:\n",
    "        theta = 450 - (theta/2)\n",
    "    \n",
    "    #center is the center of the detected object\n",
    "    #theta is the angle of it\n",
    "    return center,theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiteOut(frame):\n",
    "    #remove white stuff, return a mask of the intsresting stuff\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # define range of white color in HSV\n",
    "    # change it according to your need !\n",
    "    sensitivity = 14\n",
    "    #lower_white = np.array([0,0,255-sensitivity])\n",
    "    #upper_white = np.array([255,sensitivity,255])\n",
    "    \n",
    "    lower_white = np.array([0, 0, 255-sensitivity])\n",
    "    upper_white = np.array([180, sensitivity, 255])\n",
    "    \n",
    "    # Threshold the HSV image to get only white colors\n",
    "    mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    # Bitwise-AND mask and original image\n",
    "    #res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    \n",
    "    # applying Morphological Operator to the image to clean the image\n",
    "    kernel = np.ones((3, 3),np.uint8)\n",
    "    iteration_close = 1\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel,iterations = iteration_close)\n",
    "    iteration_open = 2\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel,iterations = iteration_open)\n",
    "    \n",
    "    # applying Morphological Operator to the image to clean the image\n",
    "    kernel = np.ones((3, 3),np.uint8)\n",
    "    iteration_close = 1\n",
    "    res = cv2.morphologyEx(res, cv2.MORPH_CLOSE, kernel,iterations = iteration_close)\n",
    "    iteration_open = 2\n",
    "    res = cv2.morphologyEx(res, cv2.MORPH_OPEN, kernel,iterations = iteration_open)    \n",
    "    \n",
    "    return mask,np.abs(255-res)\n",
    "    #1 - res is what we want, np.multiply(frame,1-res) gives what we want\n",
    "\n",
    "def rotate_bound(image, angle):\n",
    "    # grab the dimensions of the image and then determine the\n",
    "    # center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    " \n",
    "    # grab the rotation matrix (applying the negative of the\n",
    "    # angle to rotate clockwise), then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    " \n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    " \n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "    \n",
    "    diag = max(nW,nH)\n",
    " \n",
    "    # perform the actual rotation and return the image\n",
    "    #return [nW,nH],cv2.warpAffine(image, M, (nW, nH),borderValue = (255,255,255))\n",
    "    return diag,cv2.warpAffine(image, M, (diag, diag),borderValue = (255,255,255))\n",
    "\n",
    "def OverLay(background,image,center,theta,scale):\n",
    "    #first let's recize the image\n",
    "    h,w,d = image.shape\n",
    "    h = int(np.floor(h*scale))\n",
    "    w = int(np.floor(w*scale))   \n",
    "    resized  = cv2.resize(image, (w,h))\n",
    "    \n",
    "    #rows,cols,d = resized.shape\n",
    "    #M = cv2.getRotationMatrix2D((np.floor(cols/2),np.floor(rows/2)),theta,1)\n",
    "    \n",
    "    #this line needs to be changed for better performance\n",
    "    #diag = int(np.floor(np.sqrt(rows*rows+cols*cols)))\n",
    "    #diag = int(np.maximum(rows,cols))\n",
    "    #dst = cv2.warpAffine(resized,M,(diag,diag),borderValue = (255,255,255))\n",
    "    \n",
    "    diag, dst = rotate_bound(resized, theta)\n",
    "    #diag = int(np.floor(np.sqrt(nW*nW+nH*nH)))\n",
    "       \n",
    "    #h,w,d = dst.shape\n",
    "    mask,res = whiteOut(dst)\n",
    "    #imshow(res)\n",
    "    \n",
    "    x_center = center[0]\n",
    "    y_center = center[1]\n",
    "    \n",
    "    result = background.copy()\n",
    "    cols,rows,d = result.shape\n",
    "    \n",
    "    tx = np.floor(x_center - diag/2)\n",
    "    #xcenter\n",
    "    ty = np.floor(y_center - diag/2)\n",
    "    #ycenter\n",
    "    \n",
    "    \n",
    "    Ry0 = int(ty)\n",
    "    Ry1 = int(ty+diag)\n",
    "    #Ry1 = int(ty+nH)\n",
    "    Rx0 = int(tx)\n",
    "    Rx1 = int(tx+diag)\n",
    "    #Rx1 = int(tx+nW)\n",
    "    Fy0 = int(0)\n",
    "    Fy1 = int(0+diag)\n",
    "    #Fy1 = int(0+nH)\n",
    "    Fx0 = int(0)\n",
    "    Fx1 = int(0+diag)\n",
    "    #Fx1 = int(0+nW)\n",
    "    \n",
    "    \n",
    "    if tx < 0 or ty < 0 or int(tx + diag) > rows or int(ty+diag) > cols:\n",
    "        if tx < 0:\n",
    "            Rx0 = 0\n",
    "            Rx1 = int(diag-abs(tx))\n",
    "            Fx0 = int(abs(tx))\n",
    "        if ty < 0:\n",
    "            Ry0 = 0\n",
    "            Ry1 = int(diag-abs(ty))\n",
    "            Fy0 = int(abs(ty))\n",
    "        if int(tx + diag) > rows:\n",
    "            Rx0 = rows - (diag - (int(tx + diag)-rows)) \n",
    "            Rx1 = rows\n",
    "            Fx1 = int(0+diag-(int(tx+diag)-rows)) \n",
    "        if int(ty + diag) > cols:\n",
    "            Ry0 = cols - (diag - (int(ty + diag)-cols)) \n",
    "            Ry1 = cols\n",
    "            Fy1  = int(0+diag-(int(ty+diag)-cols))\n",
    "    \n",
    "    '''\n",
    "    if tx < 0 or ty < 0 or int(tx + diag) > rows or int(ty+diag) > cols:\n",
    "        if tx < 0:\n",
    "            Rx0 = 0\n",
    "            Rx1 = int(diag-abs(tx))\n",
    "            Fx0 = int(abs(tx))\n",
    "        if ty < 0:\n",
    "            Ry0 = 0\n",
    "            Ry1 = int(diag-abs(ty))\n",
    "            Fy0 = int(abs(ty))\n",
    "        if int(tx + diag) > rows:\n",
    "            Rx0 = rows - (diag - (int(tx + diag)-rows)) \n",
    "            Rx1 = rows\n",
    "            Fx1 = int(0+diag-(int(tx+diag)-rows)) \n",
    "        if int(ty + diag) > cols:\n",
    "            Ry0 = cols - (diag - (int(ty + diag)-cols)) \n",
    "            Ry1 = cols\n",
    "            Fy1  = int(0+diag-(int(ty+diag)-cols))\n",
    "    '''\n",
    "            \n",
    "    newImg = result[Ry0:Ry1,Rx0:Rx1,:]\n",
    "    dst = dst[Fy0:Fy1,Fx0:Fx1,:]\n",
    "    res = res[Fy0:Fy1,Fx0:Fx1,:]\n",
    "    #imshow(newImg)\n",
    "    #imshow(dst)\n",
    "    res2 = np.abs(255-res)\n",
    "    img2 = cv2.bitwise_and(dst,res)\n",
    "    img3 = cv2.bitwise_and(newImg,res2)\n",
    "    final = np.add(img2,img3)\n",
    "    result[Ry0:Ry1,Rx0:Rx1] = final\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScale(deArea,reArea):\n",
    "    return round(reArea/deArea,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPeaksAndValleys(samplePoints, thresh_angle, k):\n",
    "    peaks = {} # Dictionary that stores points corresponding to fingertips\n",
    "    valleys = {} # Dictionary that stores points corresponding to spaces\n",
    "\n",
    "    for j in range(len(samplePoints)):\n",
    "\n",
    "        # determine points corresponding to indices j-k, j and j+k\n",
    "        jCoord = samplePoints[j][0]\n",
    "        minusK = samplePoints[(j-k)%len(samplePoints)][0]\n",
    "        plusK = samplePoints[(j+k)%len(samplePoints)][0]\n",
    "\n",
    "        kCurv = get_angle(minusK - jCoord, plusK - jCoord)\n",
    "\n",
    "        if kCurv <= thresh_angle:\n",
    "\n",
    "            orientation = np.cross(minusK - jCoord, plusK - jCoord)\n",
    "\n",
    "            if orientation >= 0:\n",
    "                peaks = update(peaks, j, kCurv, samplePoints)\n",
    "            else:\n",
    "                valleys = update(valleys, j, kCurv, samplePoints)\n",
    "    return peaks, valleys\n",
    "\n",
    "def getHandContours(mask):\n",
    "    # Get the contour of the hand and draw it on the original image\n",
    "    im2, contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # Calculate areas\n",
    "    areas = [cv2.contourArea(cont) for cont in contours]\n",
    "    \n",
    "    # Only keep the largest contour\n",
    "    if len(contours) == 0:\n",
    "        return\n",
    "    cnt = contours[np.argmax(areas)]\n",
    "    return cnt\n",
    "\n",
    "def get_angle(v1, v2):\n",
    "    v1 = v1 / np.linalg.norm(v1) # unit vector v1\n",
    "    v2 = v2 / np.linalg.norm(v2) # unit vector v2\n",
    "    cos_theta = np.dot(v1, v2) \n",
    "    return np.arccos(cos_theta)*(180/np.pi)\n",
    "\n",
    "# Helper function to find distance between two vectors\n",
    "def dist(v1, v2):\n",
    "    return np.linalg.norm(np.array(v1)-v2)\n",
    "\n",
    "def update(pointDict, j, kCurv, samplePoints):\n",
    "    \n",
    "    for i in pointDict:\n",
    "        \n",
    "        # if index j is close to one of the stored indices \n",
    "        if abs(i-j) <= 10 or abs(i-j) >= len(samplePoints) - 10:\n",
    "            \n",
    "            # if k-curvature of point j is smaller, replace i by it\n",
    "            if kCurv < pointDict[i]:\n",
    "                pointDict[j] = kCurv\n",
    "                del pointDict[i]\n",
    "            return pointDict                        \n",
    "    pointDict[j] = kCurv\n",
    "    return pointDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = cv2.SimpleBlobDetector_Params()\n",
    "# params.filterByArea = True\n",
    "# params.minArea = 2000\n",
    "# params.filterByCircularity = True\n",
    "# params.minCircularity = 0.9\n",
    "# params.filterByConvexity = True\n",
    "# params.minConvexity = 0.9\n",
    "# params.minDistBetweenBlobs = 5000\n",
    "# params.filterByColor = True\n",
    "# params.blobColor = 0\n",
    "# detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "def segment_skin_ycrcb(img):\n",
    "    # Convert image to YCrCb\n",
    "    imageYCrCb = cv2.cvtColor(img,cv2.COLOR_BGR2YCR_CB)    \n",
    "    \n",
    "    # Constants for finding range of skin color in YCrCb\n",
    "    min_YCrCb = np.array([0,133,77],np.uint8)\n",
    "    max_YCrCb = np.array([255,173,127],np.uint8)\n",
    "\n",
    "    # Find region with skin tone in YCrCb image\n",
    "    mask = cv2.inRange(imageYCrCb,min_YCrCb,max_YCrCb)\n",
    "#     mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, None, iterations = 5)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, None, iterations = 3)\n",
    "    mask = cv2.medianBlur(mask, 5)   \n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fingers detected 1\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "hi\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "hi\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "hi\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in arccos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 4\n",
      "hi\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 5\n",
      "Number of fingers detected 5\n",
      "hi\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 5\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "hi\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "hi\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 1\n",
      "hi\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "hi\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 2\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 1\n",
      "Number of fingers detected 4\n",
      "hi\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 4\n",
      "Number of fingers detected 3\n",
      "Number of fingers detected 3\n"
     ]
    }
   ],
   "source": [
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.filterByArea = True\n",
    "params.minArea = 800\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.5\n",
    "params.filterByConvexity = False\n",
    "params.minConvexity = 0.7\n",
    "detector_pinch = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "img1 = cv2.imread(\"demo.jpg\")\n",
    "snow_video = cv2.VideoCapture('snow.mp4')\n",
    "_, background = snow_video.read()#cv2.imread(\"bk.png\")\n",
    "img1 = cv2.flip(img1,1)\n",
    "h,w,d = img1.shape\n",
    "detector = cv2.ORB_create()\n",
    "kp1, des1 = detector.detectAndCompute(img1,None)\n",
    "snow_frame_counter = 0\n",
    "background_pinch = None\n",
    "\n",
    "k = 5\n",
    "thresh_angle = 70\n",
    "\n",
    "while True:\n",
    "    ret_snow, background = snow_video.read()\n",
    "    snow_frame_counter += 1\n",
    "    if snow_frame_counter == snow_video.get(cv2.CAP_PROP_FRAME_COUNT) - 1:\n",
    "        print('hi')\n",
    "        snow_frame_counter = 0\n",
    "        snow_video.release()\n",
    "        snow_video = cv2.VideoCapture('snow.mp4')\n",
    "    \n",
    "    ret, img2 = cam.read()\n",
    "    img2_gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.flip(img2,1)\n",
    "    checker,dst,_ = orbTrack(img1,kp1,des1,img2,h,w)\n",
    "    #checker2,dst2,qp2 = orbTrack(img1,kp1,des1,img2,h,w)\n",
    "    \n",
    "    result = background.copy()\n",
    "    \n",
    "    \n",
    "    ''' Pinch Detection'''\n",
    "    \n",
    "    img2_for_pinch = cv2.medianBlur(img2,19)\n",
    "    mask_for_pinch = segment_skin_ycrcb(img2_for_pinch)\n",
    "    erosion = cv2.erode(mask_for_pinch,(15,15),iterations = 5)\n",
    "    keypoints = detector_pinch.detect(mask_for_pinch)\n",
    "    pinch_detected = False if len(keypoints) < 1 else True\n",
    "    peaks_count = 0\n",
    "    if not pinch_detected:\n",
    "        '''Finger Tracking'''\n",
    "        img2_modified= cv2.medianBlur(img2,9)\n",
    "        mask = segment_skin_ycrcb(img2_modified)\n",
    "        cnt = getHandContours(mask)\n",
    "        if cnt is None or len(cnt) <= 300:\n",
    "            print(\"No contours found\")\n",
    "        else:\n",
    "            interval = int(len(cnt)/100)\n",
    "            sample_points = cnt[0:len(cnt):interval] \n",
    "            peaks, valleys = getPeaksAndValleys(sample_points, thresh_angle, k)\n",
    "\n",
    "            print(\"Number of fingers detected %d\" % (len(peaks)))\n",
    "            peaks_count = len(peaks)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if checker != -1:\n",
    "        #center = findOrientation(qp)\n",
    "        #mask = cv2.polylines(img2,[np.int32(dst)],True,(0,255,0),5)\n",
    "        center,theta = findOrientation(dst)\n",
    "        area = recArea(dst)\n",
    "        scale = getScale(50000,area)\n",
    "        result = OverLay(background,img1,[int(center[0]),int(center[1])],theta,scale)\n",
    "\n",
    "\n",
    "        #cv2.putText(mask, str(area), (int(np.floor(center[0])),int(np.floor(center[1]))), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0, 255, 255), 2)\n",
    "        #cv2.circle(mask,(int(np.floor(center[0])),int(np.floor(center[1]))), 3, (0,0,255), -1)\n",
    "        #cv2.circle(mask,(np.floor(dst[0][1][0]),np.floor(dst[0][1][1])), 3, (0,0,255), -1)\n",
    "        #cv2.circle(mask,(qp[0][0][0],qp[0][0][q]), 63, (0,0,255), -1)\n",
    "        #mask = cv2.polylines(mask,[np.int32(dst2)],True,(0,255,0),5)\n",
    "        #print(\"YES\")\n",
    "    \n",
    "    keypressed = cv2.waitKey(5)\n",
    "    if keypressed == 32:\n",
    "        background_pinch = img2_gray\n",
    "        print('background saved')\n",
    "    if keypressed == 27:\n",
    "        break\n",
    "    cv2.putText(result,str(pinch_detected),(10,100), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,str(peaks_count),(10,300), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow('mask',result)\n",
    "    \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
